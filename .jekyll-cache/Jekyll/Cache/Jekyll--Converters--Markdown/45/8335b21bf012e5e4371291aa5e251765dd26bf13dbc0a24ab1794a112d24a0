I"ÌÌ<p><img src="http://localhost:4000/assets/images/gradientdescent/grad.gif" alt="IntroGIF" /></p>

<p>So the gradient descent is one of the best starting points that I can think of when trying to get into machine learning.</p>

<p><br /></p>

<hr />

<h2 id="theory">Theory</h2>
<h3 id="calculus">Calculus</h3>
<p>In calculus, one of the first things that one learns is to attain the minimum and/or maximum of a function. Usually, the method of choice is to take the first derivative and then set it to zero, and solve for the input argument (e.g. \(x\))</p>

<p>As an example, letâ€™s find the minimum of the function \(y(x)\)</p>

\[\begin{align*}
y(x) &amp;=  x^2 + 4x - 10 \quad (\text{Take the derivative}) \\
\frac{dy(x)}{dx} &amp;= \frac{d}{dx} \left[ x^2 + 4x - 10 \right] \\
&amp;= 2x + 4 \quad (\text{Set the derivative equal to zero}) \\
0 &amp;= 2x + 4 \\
-2x &amp;= 4 \\
x &amp;= -2
\end{align*}\]

<p>Therefore in this case, the minimum occurs at \(x = -2\)!</p>

<p>If this was a gradient descent problem, the final theoretical solution would be \(x \approx -2\), and instead of \(x\) would be the weights \(w\)</p>

<h3 id="back-to-gradient-descent">Back to Gradient Descent</h3>
<p>So that was easy! Gradient descent follows on that same concept. HOWEVER, although it tries to find the minimum, <strong>it does not know the function equivalent to \(y(x)\)</strong>. However, since it uses the gradient \(\nabla\), it uses it to walk down the hill.</p>

<p>So, in this case, we define:</p>

<table>
  <thead>
    <tr>
      <th>Variables</th>
      <th>Â </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>\(x = \text{Features}\)</td>
      <td>\(m = \text{Slope}\)</td>
    </tr>
    <tr>
      <td>\(y = \text{Label}\)</td>
      <td>\(w = [m,b] = \text{weights}\)</td>
    </tr>
    <tr>
      <td>\(b = \text{Bias}\)</td>
      <td>\(n = \text{Number of Observations}\)</td>
    </tr>
  </tbody>
</table>

<p>In this case, you will likely have \(n\) observations, and you will have a model. The model is simply a model and it is not optimized for your data. Your goal in such case is to discover the weights \(w\), such that they fit your data.</p>

<h4 id="define-model">Define Model</h4>
<p>For a linear model,</p>

\[y_{pred,i} = mx_i + b\]

<h4 id="define-residual-or-error">Define Residual or Error</h4>
<p>The residual of the prediction would be</p>

\[\text{Residual} = \text{Truth} - \text{Prediction}\]

\[\text{Residual} = y_{true,i} - y_{pred,i}\]

\[\text{Residual} = y_{true,i} - (mx_i + b)\]

<h4 id="define-cost">Define Cost</h4>
<p>For the cost function, we can use the <strong>Mean Squared Error</strong></p>

\[MSE = \frac{1}{N} \sum_{i=1}^n \text{Residual}^2\]

\[MSE = \frac{1}{N} \sum_{i=1}^n \left[ y_{true,i} - (mx_i + b) \right]^2\]

<p>You can consider your cost energy function as \(MSE\), and with that you can also compute its gradient \(\nabla MSE\)</p>

<h4 id="evolve-weights">Evolve Weights</h4>
<p>All you have to do now is to define an initial set of weights. Do you know them? Nope! So you can choose any and then you can try different initial weights \(w_0\) for different experiments. You have to also define a learning rate \(\gamma\). So with that, now you should have:</p>
<ul>
  <li>Cost function \(MSE\)</li>
  <li>Gradient of Cost Function \(\nabla MSE\)</li>
  <li>Initial Weights \(w_0\)</li>
  <li>Learning Rate \(\gamma\)</li>
</ul>

<p>Now to evolve the weights,</p>

<blockquote>
  <p>Initialize weights \(w\)<br />
for each step:<br />
Â Â Â Â Â Â Â Â  Make label predictions using \(w\)<br />
Â Â Â Â Â Â Â Â  Determine Cost (Optional)<br />
Â Â Â Â Â Â Â Â  Determine Gradient of Cost \(\nabla MSE\)<br />
Â Â Â Â Â Â Â Â  Update weights: \(w_{new} = w_{old} - \gamma \nabla MSE\)
Â Â Â Â Â Â Â Â </p>
</blockquote>

<p>After many iterations, the weights will be minimized! Letâ€™s take a look at some examples!</p>

<p><br /></p>

<hr />

<h2 id="application-simple-regression-example">Application: Simple Regression Example</h2>

<p>Letâ€™s import the libraries</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits</span> <span class="kn">import</span> <span class="n">mplot3d</span>
</code></pre></div></div>

<h3 id="problem">Problem</h3>
<p>Letâ€™s say you are given a set of data \(\textbf{x}\), where \(\textbf{x} \in \mathbb{R}^{1 \times n}\). Letâ€™s say \(x\) is the number of bananas. Along with that, it comes with labels \(y\), which indicate the number of monkeys that come to your house! We are given a plot like the one below</p>

<p>[INSERT SCATTER PLOT]</p>

<p>We are trying to setup a linear regression to the data so that you can start to make predictions. We can set the model to be a linear model</p>

\[y = m\textbf{x} + b\]

<p>which in turn can be reduced to</p>

\[y = \textbf{w} \cdot \textbf{x}\]

<p>Where we can redefine \(\textbf{x} \in \mathbb{R}^{2\times n}\), where all of the elements of the second row are \(1\)s. This way, we can say that \(\textbf{w} \in \mathbb{R}^{2 \times 1}\), creating the model</p>

<h3 id="lets-get-started">Letâ€™s Get Started!</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">Model</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">w</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">x</span><span class="p">).</span><span class="n">T</span>
    <span class="k">return</span> <span class="n">y_pred</span>
</code></pre></div></div>

<p>Our cost function is defined as</p>

\[MSE = \frac{1}{N} \sum_{i=1}^n \left[ y_{true,i} - (mx_i + b) \right]^2\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">cost_function</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">totalError</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">totalError</span> <span class="o">=</span> <span class="n">totalError</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">totalError</span><span class="o">/</span><span class="n">N</span>
</code></pre></div></div>
<p>In order to calculate the gradient, we know that our MSE for our model is dependent on $m$ and $b$,
\(MSE(m,b) = \frac{1}{N} \sum_{i=1}^n (y_i - (mx_i + b))^2\)</p>

<p>Therefore, the gradient is:
\(\nabla MSE = \begin{bmatrix} \frac{\partial MSE}{\partial m} \\
\frac{\partial MSE}{\partial b} \end{bmatrix} =
\begin{bmatrix}
\frac{1}{N} \sum (-2x_i)(y_i - (mx_i + b)) \\
\frac{1}{N} \sum (-2)(y_i - (mx_i + b)) \\
\end{bmatrix}\)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">gradient_function</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span> <span class="n">b</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">dMSE_dm</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">dMSE_db</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>  <span class="c1"># For every feature
</span>        <span class="n">dMSE_dm</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span> <span class="n">y</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">));</span>
        <span class="n">dMSE_db</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">))</span>
    <span class="n">dMSE_dm</span> <span class="o">=</span> <span class="n">dMSE_dm</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">dMSE_db</span> <span class="o">=</span> <span class="n">dMSE_db</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">dMSE_dm</span><span class="p">,</span> <span class="n">dMSE_db</span><span class="p">]</span>
</code></pre></div></div>

<p>We can then initialize the guess and the learning rate \(\gamma\)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">],[</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">learningRate</span> <span class="o">=</span> <span class="mf">0.05</span>
</code></pre></div></div>

<p>You can then run the main algorithm</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mainAlgorithm</span><span class="p">():</span>
    <span class="k">global</span> <span class="n">w</span>
    <span class="k">global</span> <span class="n">learningRate</span>
    <span class="k">global</span> <span class="n">printResults</span>

    <span class="n">cost_array</span> <span class="o">=</span> <span class="p">[];</span>
    <span class="n">label_array</span> <span class="o">=</span> <span class="p">[];</span>

    <span class="n">numSteps</span> <span class="o">=</span> <span class="mi">10000</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numSteps</span><span class="p">):</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">cost_function</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">gradient_function</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

        <span class="c1"># Append items to arrays
</span>        <span class="n">cost_array</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
        <span class="n">label_array</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">label_ser</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>

        <span class="c1"># Update Weights
</span>        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">-</span> <span class="n">grad</span><span class="o">*</span><span class="n">learningRate</span>
</code></pre></div></div>
<p>[INSERT FIGURES]</p>

<p><br /></p>

<hr />

<h2 id="application-multi-dimensional-example">Application: Multi-Dimensional Example</h2>

<p>If you are to have a dataset with multiple features \(f\), we can say that \(x \in \mathbb{R}^{f \times n}\), all we have to do is to make a more modular setup.</p>

<p>Letâ€™s import some libraries!</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">scipy.io</span> <span class="k">as</span> <span class="n">spio</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="c1"># For plotting in 3D
</span><span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
</code></pre></div></div>

<p>We can create a class <code class="language-plaintext highlighter-rouge">LinearRegression_Tool</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LinearRegression_Tool</span><span class="p">:</span>
    <span class="c1"># PARTIAL
</span></code></pre></div></div>

<p>For this class, we can create the initializer, such that it also takes care of the dimensions, making sure that all of the linear algebra will work out super nicely later on!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PARTIAL
</span><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">features</span><span class="p">,</span><span class="n">labels</span><span class="p">):</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.00005</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">features</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">arrayOnes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">features</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">feats</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">arrayOnes</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">feats</span><span class="p">.</span><span class="n">T</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">arrayOnes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">features</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">));</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">features</span><span class="p">,(</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">),</span><span class="mi">1</span><span class="p">));</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">feats</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">arrayOnes</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">feats</span><span class="p">.</span><span class="n">T</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">labels</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y_true</span> <span class="o">=</span> <span class="n">labels</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">labels</span><span class="p">,(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y_true</span> <span class="o">=</span> <span class="n">labels</span>
</code></pre></div></div>

<p>We can create some Setters and Getters</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PARTIAL
</span><span class="k">def</span> <span class="nf">setWeights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">weights</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'This is not a numpy array'</span><span class="p">)</span>
        <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">weights</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'This is not a column vector'</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">weights</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="p">.</span><span class="n">feats</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'The number of weights do not coincide with the number of features'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">weights</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">init_w</span> <span class="o">=</span> <span class="n">weights</span>
<span class="c1">#---------------------------------------------------------------------------
</span><span class="k">def</span> <span class="nf">getWeights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">w</span>
<span class="c1">#---------------------------------------------------------------------------
</span><span class="k">def</span> <span class="nf">setLearningRate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">lr</span><span class="p">):</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
<span class="c1">#---------------------------------------------------------------------------
</span><span class="k">def</span> <span class="nf">getErrorArray</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">errorArray</span>
</code></pre></div></div>

<p>We create the model, in this case a linear model</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PARTIAL
</span><span class="k">def</span> <span class="nf">Model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">w</span><span class="p">.</span><span class="n">T</span><span class="p">,</span><span class="bp">self</span><span class="p">.</span><span class="n">feats</span><span class="p">).</span><span class="n">T</span>
    <span class="k">return</span> <span class="n">y_pred</span>
</code></pre></div></div>

<p>We can create the cost function</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PARTIAL
</span><span class="k">def</span> <span class="nf">SquaredLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span>

    <span class="n">error</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y_true</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">y_pred</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">totalError</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">error</span><span class="p">)</span><span class="o">/</span><span class="n">error</span><span class="p">.</span><span class="n">size</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Total Error is %.2f'</span> <span class="o">%</span> <span class="n">totalError</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">totalError</span>
</code></pre></div></div>

<p>We can create the gradient of the cost function</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PARTIAL
</span><span class="k">def</span> <span class="nf">GradientSquaredLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">GradE</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">w</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y_true</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">Model</span><span class="p">())</span><span class="o">/</span><span class="bp">self</span><span class="p">.</span><span class="n">y_true</span><span class="p">.</span><span class="n">size</span>
    <span class="k">return</span> <span class="n">GradE</span>
</code></pre></div></div>

<p>We then create a weights updater</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PARTIAL
</span><span class="k">def</span> <span class="nf">UpdateWeights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">w</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">GradientSquaredLoss</span><span class="p">()</span>
</code></pre></div></div>

<p>Finally, we setup a evolution function</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PARTIAL
</span><span class="k">def</span> <span class="nf">Evolve_threshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span><span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">showEvolution</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="bp">self</span><span class="p">.</span><span class="n">errorArray</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_iterations</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">UpdateWeights</span><span class="p">()</span>
        <span class="n">thisError</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">SquaredLoss</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">errorArray</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">thisError</span>
        <span class="k">if</span> <span class="n">showEvolution</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">plotResults</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">thisError</span><span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">errorArray</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">:</span>
            <span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span><span class="o">-</span><span class="n">k</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">errorArray</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">errorArray</span><span class="p">[:</span><span class="o">-</span><span class="n">n</span><span class="p">]</span>
            <span class="k">break</span>
</code></pre></div></div>

<h3 id="final-code">Final Code</h3>
<p>The final code will look like the following</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LinearRegression_Tool</span><span class="p">:</span>
    <span class="c1">#---------------------------------------------------------------------------
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">features</span><span class="p">,</span><span class="n">labels</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.00005</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">features</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">arrayOnes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">features</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">feats</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">arrayOnes</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">feats</span><span class="p">.</span><span class="n">T</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">arrayOnes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">features</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">));</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">features</span><span class="p">,(</span><span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">),</span><span class="mi">1</span><span class="p">));</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">feats</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">arrayOnes</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">feats</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">feats</span><span class="p">.</span><span class="n">T</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">labels</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">y_true</span> <span class="o">=</span> <span class="n">labels</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">labels</span><span class="p">,(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span><span class="mi">1</span><span class="p">))</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">y_true</span> <span class="o">=</span> <span class="n">labels</span>
    <span class="c1">#---------------------------------------------------------------------------
</span>    <span class="k">def</span> <span class="nf">setWeights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">weights</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'This is not a numpy array'</span><span class="p">)</span>
            <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">weights</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'This is not a column vector'</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">weights</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="p">.</span><span class="n">feats</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'The number of weights do not coincide with the number of features'</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">weights</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">init_w</span> <span class="o">=</span> <span class="n">weights</span>
    <span class="c1">#---------------------------------------------------------------------------
</span>    <span class="k">def</span> <span class="nf">getWeights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">w</span>
    <span class="c1">#---------------------------------------------------------------------------
</span>    <span class="k">def</span> <span class="nf">setLearningRate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">lr</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
    <span class="c1">#---------------------------------------------------------------------------
</span>    <span class="k">def</span> <span class="nf">Model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">w</span><span class="p">.</span><span class="n">T</span><span class="p">,</span><span class="bp">self</span><span class="p">.</span><span class="n">feats</span><span class="p">).</span><span class="n">T</span>
        <span class="k">return</span> <span class="n">y_pred</span>
    <span class="c1">#---------------------------------------------------------------------------
</span>    <span class="k">def</span> <span class="nf">SquaredLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">Model</span><span class="p">()</span>

        <span class="n">error</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y_true</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">y_pred</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">totalError</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">error</span><span class="p">)</span><span class="o">/</span><span class="n">error</span><span class="p">.</span><span class="n">size</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'Total Error is %.2f'</span> <span class="o">%</span> <span class="n">totalError</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">totalError</span>
    <span class="c1">#---------------------------------------------------------------------------
</span>    <span class="k">def</span> <span class="nf">GradientSquaredLoss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">GradE</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">w</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">y_true</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">Model</span><span class="p">())</span><span class="o">/</span><span class="bp">self</span><span class="p">.</span><span class="n">y_true</span><span class="p">.</span><span class="n">size</span>
        <span class="k">return</span> <span class="n">GradE</span>
    <span class="c1">#---------------------------------------------------------------------------
</span>    <span class="k">def</span> <span class="nf">UpdateWeights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">w</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">lr</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">GradientSquaredLoss</span><span class="p">()</span>
    <span class="c1">#---------------------------------------------------------------------------
</span>    <span class="k">def</span> <span class="nf">Evolve_threshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span><span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">showEvolution</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">errorArray</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_iterations</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">UpdateWeights</span><span class="p">()</span>
            <span class="n">thisError</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">SquaredLoss</span><span class="p">()</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">errorArray</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">thisError</span>
            <span class="k">if</span> <span class="n">showEvolution</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">plotResults</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">thisError</span><span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">errorArray</span><span class="p">[</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">threshold</span><span class="p">:</span>
                <span class="n">n</span> <span class="o">=</span> <span class="mi">1000</span><span class="o">-</span><span class="n">k</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">errorArray</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">errorArray</span><span class="p">[:</span><span class="o">-</span><span class="n">n</span><span class="p">]</span>
                <span class="k">break</span>
    <span class="c1">#---------------------------------------------------------------------------
</span>    <span class="k">def</span> <span class="nf">getErrorArray</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">errorArray</span>
    <span class="c1">#---------------------------------------------------------------------------
</span>    <span class="k">def</span> <span class="nf">plotResults</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">w</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># This is a 2D plot
</span>            <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
            <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">feats</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span><span class="bp">self</span><span class="p">.</span><span class="n">y_true</span><span class="p">,</span><span class="s">'bo-'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s">"True Data"</span><span class="p">)</span>
            <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">feats</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span><span class="bp">self</span><span class="p">.</span><span class="n">Model</span><span class="p">(),</span><span class="s">'rx--'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s">'Predictions'</span><span class="p">)</span>
            <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">feats</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span><span class="n">np</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">init_w</span><span class="p">.</span><span class="n">T</span><span class="p">,</span><span class="bp">self</span><span class="p">.</span><span class="n">feats</span><span class="p">).</span><span class="n">T</span><span class="p">,</span><span class="s">'g.--'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s">'Initial'</span><span class="p">)</span>

            <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
            <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Input Data'</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="p">.</span><span class="n">w</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="c1"># This is a 3D plot
</span>            <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s">'3d'</span><span class="p">)</span>
            <span class="c1"># FINISH THIS
</span>        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">'This data cannot be displayed in a graph. It has dimensions higher than possible'</span><span class="p">)</span>

</code></pre></div></div>

<h3 id="usage">Usage</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load a .mat file
</span><span class="n">ls_lm</span> <span class="o">=</span> <span class="n">spio</span><span class="p">.</span><span class="n">loadmat</span><span class="p">(</span><span class="s">'./ls_lm.mat'</span><span class="p">,</span><span class="n">squeeze_me</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">ls_lm</span><span class="p">[</span><span class="s">'x'</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">ls_lm</span><span class="p">[</span><span class="s">'y'</span><span class="p">]</span>

<span class="c1"># Create the class as a tool
</span><span class="n">LinReg</span> <span class="o">=</span> <span class="n">LinearRegression_Tool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Perform the actions
</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">],[</span><span class="mi">5</span><span class="p">]])</span>
<span class="n">LinReg</span><span class="p">.</span><span class="n">setWeights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
<span class="n">LinReg</span><span class="p">.</span><span class="n">Evolve_threshold</span><span class="p">()</span>
<span class="n">errors</span> <span class="o">=</span> <span class="n">LinReg</span><span class="p">.</span><span class="n">getErrorArray</span><span class="p">()</span>

<span class="c1"># Get the final weights
</span><span class="n">finalWeights</span> <span class="o">=</span> <span class="n">LinReg</span><span class="p">.</span><span class="n">getWeights</span><span class="p">()</span>

<span class="c1"># Plot the results
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">errors</span><span class="p">)</span>
<span class="n">LinReg</span><span class="p">.</span><span class="n">plotResults</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="optimization-parameters--instability">Optimization Parameters &amp; Instability</h2>
:ET